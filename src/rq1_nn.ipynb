{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "\n",
    "from data_preparation import *\n",
    "from util import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T09:03:33.767852400Z",
     "start_time": "2023-06-26T09:03:32.884431800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1638 entries, 1909 to 768\n",
      "Data columns (total 31 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   storageRegion        1638 non-null   object        \n",
      " 1   storageProvider      1638 non-null   object        \n",
      " 2   functionId           1638 non-null   object        \n",
      " 3   functionName         1638 non-null   object        \n",
      " 4   functionType         1638 non-null   object        \n",
      " 5   RTT                  1638 non-null   float64       \n",
      " 6   loopCounter          1638 non-null   float64       \n",
      " 7   maxLoopCounter       1638 non-null   float64       \n",
      " 8   startTime            1638 non-null   datetime64[ns]\n",
      " 9   endTime              1638 non-null   datetime64[ns]\n",
      " 10  upAll                1638 non-null   float64       \n",
      " 11  downAll              1638 non-null   float64       \n",
      " 12  numberDownloadFiles  1638 non-null   int64         \n",
      " 13  sizeDownloadInMB     1638 non-null   float64       \n",
      " 14  numberUploadFiles    1638 non-null   int64         \n",
      " 15  sizeUploadInMB       1638 non-null   float64       \n",
      " 16  functionProvider     1638 non-null   object        \n",
      " 17  functionRegion       1638 non-null   object        \n",
      " 18  wfType               1638 non-null   object        \n",
      " 19  functionRegionEnc    1638 non-null   int32         \n",
      " 20  storageRegionEnc     1638 non-null   int32         \n",
      " 21  functionProviderEnc  1638 non-null   int32         \n",
      " 22  storageProviderEnc   1638 non-null   int32         \n",
      " 23  functionNameEnc      1638 non-null   int32         \n",
      " 24  functionTypeEnc      1638 non-null   int32         \n",
      " 25  wfTypeEnc            1638 non-null   int32         \n",
      " 26  dayofweek            1638 non-null   int32         \n",
      " 27  timeofday            1638 non-null   int32         \n",
      " 28  ct                   1638 non-null   float64       \n",
      " 29  datatransferTime     1638 non-null   float64       \n",
      " 30  kFoldGroupEnc        1638 non-null   int32         \n",
      "dtypes: datetime64[ns](2), float64(9), int32(10), int64(2), object(8)\n",
      "memory usage: 345.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df = load_preprocessed_dataset(remove_duplicates=True)\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T09:03:33.781271Z",
     "start_time": "2023-06-26T09:03:33.767852400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "input_cols = get_function_related_cols() + get_storage_related_cols() + get_time_related_cols() + get_concurrency_related_cols()\n",
    "output_col_rtt = 'RTT'\n",
    "group_col = 'kFoldGroupEnc'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T09:03:34.551191100Z",
     "start_time": "2023-06-26T09:03:34.545688100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X_train, y_train, groups_train, X_test, y_test, _, df_test = train_test_split_with_criterion(\n",
    "    lambda x: (x['wfType'] == 'bwa' and x['functionProvider'] == 'AWS'), df, input_cols, output_col_rtt, group_col)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T09:03:35.125723500Z",
     "start_time": "2023-06-26T09:03:35.110652100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "def measure(model, plot=True,X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test):\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "    model.to(device=device)\n",
    "    loss_fn = nn.MSELoss()  # mean square error\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    n_epochs = 500  # number of epochs to run\n",
    "    batch_size = 10  # size of each batch\n",
    "    batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "\n",
    "    # Hold the best model\n",
    "    best_mse = np.inf  # init to infinity\n",
    "    best_weights = None\n",
    "    history = []\n",
    "    torch_X_train = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "    torch_y_train = torch.tensor(y_train, dtype=torch.float32, device=device).reshape(-1, 1)\n",
    "    torch_X_test = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "    torch_y_test = torch.tensor(y_test, dtype=torch.float32, device=device).reshape(-1, 1)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "            bar.set_description(f\"Epoch {epoch}\")\n",
    "            for start in bar:\n",
    "                # take a batch\n",
    "                X_batch = torch_X_train[start:start + batch_size]\n",
    "                y_batch = torch_y_train[start:start + batch_size]\n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "                # print progress\n",
    "                bar.set_postfix(mse=float(loss))\n",
    "        # evaluate accuracy at end of each epoch\n",
    "        model.eval()\n",
    "\n",
    "        y_pred = model(torch_X_test)\n",
    "        mse = loss_fn(y_pred, torch_y_test)\n",
    "        mse = float(mse)\n",
    "        history.append(mse)\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # restore model and return best accuracy\n",
    "    y_pred = model(torch_X_test)\n",
    "\n",
    "\n",
    "    rmse = np.sqrt(s_m.mean_squared_error(torch_y_test.detach().cpu().numpy(),\n",
    "                                  y_pred.detach().cpu()))\n",
    "\n",
    "    mae = s_m.mean_absolute_error(torch_y_test.detach().cpu().numpy(), y_pred.detach().cpu().numpy())\n",
    "    mape = s_m.mean_absolute_percentage_error(torch_y_test.detach().cpu().numpy(),\n",
    "                                                            y_pred.detach().cpu().numpy())\n",
    "    return rmse, mae, mape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T09:03:35.874227300Z",
     "start_time": "2023-06-26T09:03:35.872167600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "\n",
    "    def append_linear_layer_stack(self, in_size, out_size, activation, dropout):\n",
    "        new_layer = nn.Sequential(nn.Linear(in_size, out_size),\n",
    "                                  activation,\n",
    "                                  nn.Dropout1d(0.1) if dropout else nn.Identity())\n",
    "        self.layer_stack.append(new_layer)\n",
    "\n",
    "    def __init__(self, activation, hidden_width=200, hidden_depth = 2, dropout=False, input_dim=len(input_cols)):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.layer_stack = []\n",
    "\n",
    "        self.append_linear_layer_stack(input_dim, hidden_width, activation, dropout)\n",
    "        for _ in range(hidden_depth - 1):\n",
    "            self.append_linear_layer_stack(hidden_width, hidden_width, activation, dropout)\n",
    "\n",
    "        self.layer_stack.append(nn.Linear(hidden_width, 1))\n",
    "\n",
    "        self.layers = nn.Sequential(*self.layer_stack)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers.forward(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T09:03:36.695019800Z",
     "start_time": "2023-06-26T09:03:36.691018Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def eval_num_layers(num_layers=2):\n",
    "    print(num_layers, \" layers\")\n",
    "    for layer in [10, 50, 100, 500, 1000, 2000]:\n",
    "        for activationName, activation in [(\"ReLU\", nn.ReLU()), (\"Sigmoid\", nn.Sigmoid())]:\n",
    "            for dropouts in [False, True]:\n",
    "                rmse, mae, mape = measure(NN(activation, layer, num_layers, dropouts))\n",
    "                method = activationName\n",
    "                if dropouts:\n",
    "                    method += \" + dropouts\"\n",
    "                metric = \"{rmse:.2f} & {mae:.2f} & {mape:.2f} \\\\\\\\\"\n",
    "\n",
    "                print(tuple([layer for i in range(num_layers)]), \" & \", method + \" & \" , metric.format(rmse=rmse, mae=mae, mape=mape))\n",
    "        print(\"\\\\midrule\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T09:26:35.607464900Z",
     "start_time": "2023-06-26T09:26:35.586087300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  layers\n",
      "(10, 10)  &  ReLU &  23.77 & 21.90 & 3.77 \\\\\n",
      "(10, 10)  &  ReLU + dropouts &  10.76 & 8.68 & 0.64 \\\\\n",
      "(10, 10)  &  Sigmoid &  16.01 & 14.62 & 2.59 \\\\\n",
      "(10, 10)  &  Sigmoid + dropouts &  15.24 & 13.78 & 2.47 \\\\\n",
      "\\midrule\n",
      "(50, 50)  &  ReLU &  28.03 & 27.07 & 4.35 \\\\\n",
      "(50, 50)  &  ReLU + dropouts &  21.32 & 20.02 & 3.40 \\\\\n",
      "(50, 50)  &  Sigmoid &  30.57 & 29.85 & 4.66 \\\\\n",
      "(50, 50)  &  Sigmoid + dropouts &  27.49 & 26.69 & 4.23 \\\\\n",
      "\\midrule\n",
      "(100, 100)  &  ReLU &  28.04 & 27.12 & 4.35 \\\\\n",
      "(100, 100)  &  ReLU + dropouts &  21.11 & 19.95 & 3.35 \\\\\n",
      "(100, 100)  &  Sigmoid &  30.85 & 30.13 & 4.70 \\\\\n",
      "(100, 100)  &  Sigmoid + dropouts &  27.61 & 26.81 & 4.25 \\\\\n",
      "\\midrule\n",
      "(500, 500)  &  ReLU &  23.81 & 22.80 & 3.73 \\\\\n",
      "(500, 500)  &  ReLU + dropouts &  12.27 & 10.61 & 2.02 \\\\\n",
      "(500, 500)  &  Sigmoid &  30.91 & 30.20 & 4.71 \\\\\n",
      "(500, 500)  &  Sigmoid + dropouts &  26.97 & 26.15 & 4.16 \\\\\n",
      "\\midrule\n",
      "(1000, 1000)  &  ReLU &  21.69 & 20.66 & 3.42 \\\\\n",
      "(1000, 1000)  &  ReLU + dropouts &  10.70 & 9.10 & 1.78 \\\\\n",
      "(1000, 1000)  &  Sigmoid &  30.97 & 30.27 & 4.72 \\\\\n",
      "(1000, 1000)  &  Sigmoid + dropouts &  27.12 & 26.31 & 4.18 \\\\\n",
      "\\midrule\n",
      "(2000, 2000)  &  ReLU &  24.92 & 23.77 & 3.92 \\\\\n",
      "(2000, 2000)  &  ReLU + dropouts &  11.76 & 9.74 & 0.73 \\\\\n",
      "(2000, 2000)  &  Sigmoid &  31.08 & 30.37 & 4.74 \\\\\n",
      "(2000, 2000)  &  Sigmoid + dropouts &  27.37 & 26.56 & 4.22 \\\\\n",
      "\\midrule\n"
     ]
    }
   ],
   "source": [
    "eval_num_layers(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T09:22:00.396898100Z",
     "start_time": "2023-06-26T09:03:38.249812300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  layers\n",
      "(10, 10, 10)  &  ReLU &  28.03 & 26.74 & 4.41 \\\\\n",
      "(10, 10, 10)  &  ReLU + dropouts &  18.45 & 16.68 & 3.00 \\\\\n",
      "(10, 10, 10)  &  Sigmoid &  16.85 & 15.52 & 2.71 \\\\\n",
      "(10, 10, 10)  &  Sigmoid + dropouts &  16.03 & 14.64 & 2.59 \\\\\n",
      "\\midrule\n",
      "(50, 50, 50)  &  ReLU &  27.47 & 26.40 & 4.29 \\\\\n",
      "(50, 50, 50)  &  ReLU + dropouts &  18.23 & 16.75 & 2.95 \\\\\n",
      "(50, 50, 50)  &  Sigmoid &  30.55 & 29.83 & 4.66 \\\\\n",
      "(50, 50, 50)  &  Sigmoid + dropouts &  27.54 & 26.74 & 4.24 \\\\\n",
      "\\midrule\n",
      "(100, 100, 100)  &  ReLU &  27.22 & 26.13 & 4.26 \\\\\n",
      "(100, 100, 100)  &  ReLU + dropouts &  17.78 & 16.27 & 2.88 \\\\\n",
      "(100, 100, 100)  &  Sigmoid &  30.84 & 30.12 & 4.70 \\\\\n",
      "(100, 100, 100)  &  Sigmoid + dropouts &  27.72 & 26.92 & 4.27 \\\\\n",
      "\\midrule\n",
      "(500, 500, 500)  &  ReLU &  30.81 & 30.10 & 4.70 \\\\\n",
      "(500, 500, 500)  &  ReLU + dropouts &  26.92 & 26.10 & 4.15 \\\\\n",
      "(500, 500, 500)  &  Sigmoid &  30.90 & 30.19 & 4.71 \\\\\n",
      "(500, 500, 500)  &  Sigmoid + dropouts &  27.06 & 26.25 & 4.17 \\\\\n",
      "\\midrule\n",
      "(1000, 1000, 1000)  &  ReLU &  30.81 & 30.10 & 4.70 \\\\\n",
      "(1000, 1000, 1000)  &  ReLU + dropouts &  26.93 & 26.11 & 4.16 \\\\\n",
      "(1000, 1000, 1000)  &  Sigmoid &  30.96 & 30.25 & 4.72 \\\\\n",
      "(1000, 1000, 1000)  &  Sigmoid + dropouts &  27.15 & 26.34 & 4.19 \\\\\n",
      "\\midrule\n",
      "(2000, 2000, 2000)  &  ReLU &  30.79 & 30.08 & 4.69 \\\\\n",
      "(2000, 2000, 2000)  &  ReLU + dropouts &  26.89 & 26.07 & 4.15 \\\\\n",
      "(2000, 2000, 2000)  &  Sigmoid &  31.07 & 30.37 & 4.73 \\\\\n",
      "(2000, 2000, 2000)  &  Sigmoid + dropouts &  27.32 & 26.51 & 4.21 \\\\\n",
      "\\midrule\n"
     ]
    }
   ],
   "source": [
    "eval_num_layers(3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T09:50:16.569453400Z",
     "start_time": "2023-06-26T09:26:38.644336100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  layers\n",
      "(10, 10, 10, 10)  &  ReLU &  28.67 & 27.57 & 4.47 \\\\\n",
      "(10, 10, 10, 10)  &  ReLU + dropouts &  15.44 & 13.60 & 2.54 \\\\\n",
      "(10, 10, 10, 10)  &  Sigmoid &  16.24 & 14.87 & 2.62 \\\\\n",
      "(10, 10, 10, 10)  &  Sigmoid + dropouts &  15.47 & 14.03 & 2.51 \\\\\n",
      "\\midrule\n",
      "(50, 50, 50, 50)  &  ReLU &  28.35 & 27.46 & 4.39 \\\\\n",
      "(50, 50, 50, 50)  &  ReLU + dropouts &  15.26 & 13.70 & 2.49 \\\\\n",
      "(50, 50, 50, 50)  &  Sigmoid &  30.55 & 29.83 & 4.66 \\\\\n",
      "(50, 50, 50, 50)  &  Sigmoid + dropouts &  27.50 & 26.70 & 4.24 \\\\\n",
      "\\midrule\n",
      "(100, 100, 100, 100)  &  ReLU &  28.26 & 27.35 & 4.38 \\\\\n",
      "(100, 100, 100, 100)  &  ReLU + dropouts &  14.90 & 13.32 & 2.43 \\\\\n",
      "(100, 100, 100, 100)  &  Sigmoid &  30.84 & 30.12 & 4.70 \\\\\n",
      "(100, 100, 100, 100)  &  Sigmoid + dropouts &  27.64 & 26.84 & 4.25 \\\\\n",
      "\\midrule\n",
      "(500, 500, 500, 500)  &  ReLU &  30.61 & 29.89 & 4.67 \\\\\n",
      "(500, 500, 500, 500)  &  ReLU + dropouts &  25.42 & 24.55 & 3.94 \\\\\n",
      "(500, 500, 500, 500)  &  Sigmoid &  30.90 & 30.19 & 4.71 \\\\\n",
      "(500, 500, 500, 500)  &  Sigmoid + dropouts &  26.81 & 25.99 & 4.14 \\\\\n",
      "\\midrule\n",
      "(1000, 1000, 1000, 1000)  &  ReLU &  30.52 & 29.80 & 4.66 \\\\\n",
      "(1000, 1000, 1000, 1000)  &  ReLU + dropouts &  23.98 & 23.06 & 3.74 \\\\\n",
      "(1000, 1000, 1000, 1000)  &  Sigmoid &  30.96 & 30.25 & 4.72 \\\\\n",
      "(1000, 1000, 1000, 1000)  &  Sigmoid + dropouts &  26.77 & 25.95 & 4.13 \\\\\n",
      "\\midrule\n",
      "(2000, 2000, 2000, 2000)  &  ReLU &  30.43 & 29.71 & 4.64 \\\\\n",
      "(2000, 2000, 2000, 2000)  &  ReLU + dropouts &  12.60 & 10.73 & 0.86 \\\\\n",
      "(2000, 2000, 2000, 2000)  &  Sigmoid &  31.08 & 30.37 & 4.73 \\\\\n",
      "(2000, 2000, 2000, 2000)  &  Sigmoid + dropouts &  26.74 & 25.92 & 4.13 \\\\\n",
      "\\midrule\n"
     ]
    }
   ],
   "source": [
    "eval_num_layers(4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T10:35:25.325597300Z",
     "start_time": "2023-06-26T10:03:50.403137400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  layers\n",
      "(10,)  &  ReLU &  30.14 & 28.20 & 4.75 \\\\\n",
      "(10,)  &  ReLU + dropouts &  24.38 & 21.98 & 3.90 \\\\\n",
      "(10,)  &  Sigmoid &  6.61 & 5.61 & 0.92 \\\\\n",
      "(10,)  &  Sigmoid + dropouts &  6.60 & 5.58 & 0.90 \\\\\n",
      "\\midrule\n",
      "(50,)  &  ReLU &  10.59 & 8.92 & 0.85 \\\\\n",
      "(50,)  &  ReLU + dropouts &  7.91 & 6.28 & 0.58 \\\\\n",
      "(50,)  &  Sigmoid &  27.45 & 26.64 & 4.23 \\\\\n",
      "(50,)  &  Sigmoid + dropouts &  24.66 & 23.76 & 3.83 \\\\\n",
      "\\midrule\n",
      "(100,)  &  ReLU &  13.59 & 12.07 & 1.82 \\\\\n",
      "(100,)  &  ReLU + dropouts &  9.68 & 7.53 & 1.00 \\\\\n",
      "(100,)  &  Sigmoid &  30.32 & 29.59 & 4.63 \\\\\n",
      "(100,)  &  Sigmoid + dropouts &  26.61 & 25.78 & 4.11 \\\\\n",
      "\\midrule\n",
      "(500,)  &  ReLU &  36.88 & 29.67 & 4.69 \\\\\n",
      "(500,)  &  ReLU + dropouts &  86.39 & 72.03 & 7.52 \\\\\n",
      "(500,)  &  Sigmoid &  30.89 & 30.18 & 4.71 \\\\\n",
      "(500,)  &  Sigmoid + dropouts &  26.76 & 25.93 & 4.13 \\\\\n",
      "\\midrule\n",
      "(1000,)  &  ReLU &  22.48 & 18.80 & 3.05 \\\\\n",
      "(1000,)  &  ReLU + dropouts &  26.28 & 21.97 & 3.92 \\\\\n",
      "(1000,)  &  Sigmoid &  30.95 & 30.24 & 4.72 \\\\\n",
      "(1000,)  &  Sigmoid + dropouts &  26.82 & 26.00 & 4.14 \\\\\n",
      "\\midrule\n",
      "(2000,)  &  ReLU &  25.03 & 19.91 & 1.61 \\\\\n",
      "(2000,)  &  ReLU + dropouts &  51.82 & 44.27 & 6.18 \\\\\n",
      "(2000,)  &  Sigmoid &  31.06 & 30.35 & 4.73 \\\\\n",
      "(2000,)  &  Sigmoid + dropouts &  26.96 & 26.14 & 4.16 \\\\\n",
      "\\midrule\n"
     ]
    }
   ],
   "source": [
    "eval_num_layers(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T10:03:50.397892700Z",
     "start_time": "2023-06-26T09:50:16.577497600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
