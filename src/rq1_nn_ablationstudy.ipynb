{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "\n",
    "from data_preparation import *\n",
    "from util import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T10:22:50.836800300Z",
     "start_time": "2023-06-26T10:22:49.826732100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1638 entries, 1909 to 768\n",
      "Data columns (total 31 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   storageRegion        1638 non-null   object        \n",
      " 1   storageProvider      1638 non-null   object        \n",
      " 2   functionId           1638 non-null   object        \n",
      " 3   functionName         1638 non-null   object        \n",
      " 4   functionType         1638 non-null   object        \n",
      " 5   RTT                  1638 non-null   float64       \n",
      " 6   loopCounter          1638 non-null   float64       \n",
      " 7   maxLoopCounter       1638 non-null   float64       \n",
      " 8   startTime            1638 non-null   datetime64[ns]\n",
      " 9   endTime              1638 non-null   datetime64[ns]\n",
      " 10  upAll                1638 non-null   float64       \n",
      " 11  downAll              1638 non-null   float64       \n",
      " 12  numberDownloadFiles  1638 non-null   int64         \n",
      " 13  sizeDownloadInMB     1638 non-null   float64       \n",
      " 14  numberUploadFiles    1638 non-null   int64         \n",
      " 15  sizeUploadInMB       1638 non-null   float64       \n",
      " 16  functionProvider     1638 non-null   object        \n",
      " 17  functionRegion       1638 non-null   object        \n",
      " 18  wfType               1638 non-null   object        \n",
      " 19  functionRegionEnc    1638 non-null   int32         \n",
      " 20  storageRegionEnc     1638 non-null   int32         \n",
      " 21  functionProviderEnc  1638 non-null   int32         \n",
      " 22  storageProviderEnc   1638 non-null   int32         \n",
      " 23  functionNameEnc      1638 non-null   int32         \n",
      " 24  functionTypeEnc      1638 non-null   int32         \n",
      " 25  wfTypeEnc            1638 non-null   int32         \n",
      " 26  dayofweek            1638 non-null   int32         \n",
      " 27  timeofday            1638 non-null   int32         \n",
      " 28  ct                   1638 non-null   float64       \n",
      " 29  datatransferTime     1638 non-null   float64       \n",
      " 30  kFoldGroupEnc        1638 non-null   int32         \n",
      "dtypes: datetime64[ns](2), float64(9), int32(10), int64(2), object(8)\n",
      "memory usage: 345.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df = load_preprocessed_dataset(remove_duplicates=True)\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T10:22:50.858267500Z",
     "start_time": "2023-06-26T10:22:50.833800600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "input_cols = get_function_related_cols()\n",
    "output_col_rtt = 'RTT'\n",
    "group_col = 'kFoldGroupEnc'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T10:22:50.858267500Z",
     "start_time": "2023-06-26T10:22:50.846102400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "def measure(model, X_train, y_train, X_test, y_test):\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "    model.to(device=device)\n",
    "    loss_fn = nn.MSELoss()  # mean square error\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    n_epochs = 500  # number of epochs to run\n",
    "    batch_size = 10  # size of each batch\n",
    "    batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "\n",
    "    # Hold the best model\n",
    "    best_mse = np.inf  # init to infinity\n",
    "    best_weights = None\n",
    "    history = []\n",
    "    torch_X_train = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "    torch_y_train = torch.tensor(y_train, dtype=torch.float32, device=device).reshape(-1, 1)\n",
    "    torch_X_test = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "    torch_y_test = torch.tensor(y_test, dtype=torch.float32, device=device).reshape(-1, 1)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "            bar.set_description(f\"Epoch {epoch}\")\n",
    "            for start in bar:\n",
    "                # take a batch\n",
    "                X_batch = torch_X_train[start:start + batch_size]\n",
    "                y_batch = torch_y_train[start:start + batch_size]\n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "                # print progress\n",
    "                bar.set_postfix(mse=float(loss))\n",
    "        # evaluate accuracy at end of each epoch\n",
    "        model.eval()\n",
    "        y_pred = model(torch_X_test)\n",
    "        mse = loss_fn(y_pred, torch_y_test)\n",
    "        mse = float(mse)\n",
    "        history.append(mse)\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # restore model and return best accuracy\n",
    "    y_pred = model(torch_X_test)\n",
    "\n",
    "\n",
    "    rmse = np.sqrt(s_m.mean_squared_error(torch_y_test.detach().cpu().numpy(),\n",
    "                                  y_pred.detach().cpu()))\n",
    "\n",
    "    mae = s_m.mean_absolute_error(torch_y_test.detach().cpu().numpy(), y_pred.detach().cpu().numpy())\n",
    "    mape = s_m.mean_absolute_percentage_error(torch_y_test.detach().cpu().numpy(),\n",
    "                                                            y_pred.detach().cpu().numpy())\n",
    "    return rmse, mae, mape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T10:22:52.175142800Z",
     "start_time": "2023-06-26T10:22:52.156267100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "\n",
    "    def append_linear_layer_stack(self, in_size, out_size, activation, dropout):\n",
    "        new_layer = nn.Sequential(nn.Linear(in_size, out_size),\n",
    "                                  activation,\n",
    "                                  nn.Dropout1d(0.1) if dropout else nn.Identity())\n",
    "        self.layer_stack.append(new_layer)\n",
    "\n",
    "    def __init__(self, activation, hidden_width=200, hidden_depth = 2, dropout=False, input_dim=len(input_cols)):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.layer_stack = []\n",
    "\n",
    "        self.append_linear_layer_stack(input_dim, hidden_width, activation, dropout)\n",
    "        for _ in range(hidden_depth - 1):\n",
    "            self.append_linear_layer_stack(hidden_width, hidden_width, activation, dropout)\n",
    "\n",
    "        self.layer_stack.append(nn.Linear(hidden_width, 1))\n",
    "\n",
    "        self.layers = nn.Sequential(*self.layer_stack)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers.forward(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T10:22:52.673048400Z",
     "start_time": "2023-06-26T10:22:52.666545300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def ablation_study_ann50(input_cols):\n",
    "    X_train, y_train, groups_train, X_test, y_test, _, df_test = train_test_split_with_criterion(lambda x: (x['wfType'] == 'bwa' and x['functionProvider'] == 'AWS'), df, input_cols, output_col_rtt, group_col)\n",
    "\n",
    "    rmse, mae, mape = measure(NN(nn.ReLU(), hidden_width=50, hidden_depth=1, dropout=True, input_dim=len(input_cols)),\n",
    "                              X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n",
    "    print('%.2f & %.2f & %.2f \\\\\\\\' % (rmse, mae, mape))\n",
    "\n",
    "def ablation_study_ann10(input_cols):\n",
    "    X_train, y_train, groups_train, X_test, y_test, _, df_test = train_test_split_with_criterion(lambda x: (x['wfType'] == 'bwa' and x['functionProvider'] == 'AWS'), df, input_cols, output_col_rtt, group_col)\n",
    "\n",
    "    rmse, mae, mape = measure(NN(nn.Sigmoid(), hidden_width=10, hidden_depth=1, dropout=True, input_dim=len(input_cols)),\n",
    "                              X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n",
    "    print('%.2f & %.2f & %.2f \\\\\\\\' % (rmse, mae, mape))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T10:27:52.733608100Z",
     "start_time": "2023-06-26T10:27:52.730283900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.78 & 8.66 & 1.76 \\\\\n"
     ]
    }
   ],
   "source": [
    "ablation_study_ann50(get_function_related_cols())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T10:23:37.565584500Z",
     "start_time": "2023-06-26T10:22:56.180453700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.56 & 5.47 & 0.98 \\\\\n"
     ]
    }
   ],
   "source": [
    "ablation_study_ann50(get_function_related_cols() + get_storage_related_cols())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T10:24:30.201917Z",
     "start_time": "2023-06-26T10:23:37.564584300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.44 & 3.81 & 0.49 \\\\\n"
     ]
    }
   ],
   "source": [
    "ablation_study_ann50(get_function_related_cols() + get_storage_related_cols() + get_concurrency_related_cols())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T10:25:39.775696700Z",
     "start_time": "2023-06-26T10:24:30.200917Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.11 & 6.09 & 0.94 \\\\\n"
     ]
    }
   ],
   "source": [
    "ablation_study_ann50(get_function_related_cols() + get_storage_related_cols() + get_time_related_cols())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T10:27:52.730283900Z",
     "start_time": "2023-06-26T10:26:45.104333200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.22 & 9.02 & 1.89 \\\\\n",
      "8.83 & 7.62 & 1.43 \\\\\n",
      "9.40 & 8.04 & 1.52 \\\\\n",
      "8.34 & 7.23 & 1.39 \\\\\n"
     ]
    }
   ],
   "source": [
    "ablation_study_ann10(get_function_related_cols())\n",
    "ablation_study_ann10(get_function_related_cols() + get_storage_related_cols())\n",
    "ablation_study_ann10(get_function_related_cols() + get_storage_related_cols() + get_concurrency_related_cols())\n",
    "ablation_study_ann10(get_function_related_cols() + get_storage_related_cols() + get_time_related_cols())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T10:32:24.428384300Z",
     "start_time": "2023-06-26T10:27:52.732608100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
